dev_mul <- (x - mean(x)) * (y-mean(y))
square <- x_dev **
square <- x_dev ** 2
dev_mul <- (x - mean(x)) * (y-mean(y))
square <- x_dev ** 2
df <- data.frame(x, y, x_dev, y_dev, dev_mul, square)
df
mean(df$x_dev)
mean(df$x)
mean(df$y)
mean(df$x_dev)
sum(df$dev_mul)
sum(df$square) # 1000
940 / 1000
b0 = 118 - 0.94 * 130
b0
yh = -4.2 + 0.94 * newx
newx = 117
yh = -4.2 + 0.94 * newx
yh
plot(x, y)
lmodel <- lm(x, y)
lmodel <- lm(y ~ x)
lmodel
abline(lmodel, col="blue")
plot(weight ~ height, data = women)
lmodel <- lm(weight ~ height, data = women)
lmodel
abline(lmodel, col = "red")
summary(lmodel)
cor.test(women$weight, women$height)
0.9954948 ** 2
summary(lmodel)
cor.test(women$weight, women$height) # cor : 상관계수 값, 0.9954948
plot(lmodel)
plot(lmodel)
summary(lmodel)
cor.test(women$weight, women$height) # cor : 상관계수 값, 0.9954948
0.9954948 ** 2 # r을 제곱한 것. R-squared.
plot(lmodel)
par(mfrow = c(2,2))
plot(lmodel)
네 번째 차트의 우측 상단과 우측 하단에는 선으로 쿡의 거리Cook’s Distance가 표시되어 있다. 쿡의 거리는 회귀 직선의 모양(기울기나 절편 등)에 크게 영향을 끼치는 점들을 찾는 방법이다. 쿡의 거리는 레버리지와 잔차에 비례하므로 두 값이 큰 우측 상단과 우측 하단에 쿡의 거리가 큰 값들이 위치하게 된다. 이 차트에 더 관심이 있는 독자는 인터넷에 공개된 책자인 <Advanced Statistical Modelling>[9]을 참고하거나, 그림과 예제로 매우 잘 설명한 같은 강의의 PPT 슬라이드[10]에서 이상치 진단에 대한 내용을 참고하기 바란다.
# 선형성에 문제가 있을 경우에는 다항회귀를 수행
lmodel2 <- lm(weight ~ height + I(height ^ 2), data = women)
summary(lmodel2)
plot(lmodel2)
plot(lmodel2, which = c(4, 6))
#상관관계 확인
cor(result)
x = result$적절성
y = result$만족도
x = result$적절성
y = result$만족도
x = result$적절성
y = result$만족도
df <- data.frame(x, y)
df
# 단순선형회귀 모델 작성
model <- lm(formula = y ~ x, data =df)
model
summary(model)
options(scipen = 999)
summary(model)
plot(y ~ x, data = df)
abline(model, col = "blue")
plot(jitter(y,5) ~ jitter(x,5), df)
plot(jitter(y,5) ~ jitter(x,5), df)
sunflowerplot(df)
cat('만족도', yh)
# 예측 :
newx <- 5.4
yh <- 0.77886 + 0.73928 * newx
cat('만족도', yh)
names(iris)
cor(iris$Sepal.Length, iris$Sepal.Width)
cor(iris$Sepal.Length, iris$Petal.Length)
result <- lm(formula = Sepal.Length ~ Sepal.width, data = iris)
# 상관관계 분석
cor(iris$Sepal.Length, iris$Sepal.Width) # -0.1175698
cor(iris$Sepal.Length, iris$Petal.Length) # 0.8717538
result <- lm(formula = Sepal.Length ~ Sepal.width, data = iris)
result <- lm(formula = Sepal.Length ~ Sepal.width, data = iris)
names(iris)
result <- lm(formula = Sepal.Length ~ Sepal.width, data = iris)
# 상관관계 분석
cor(iris$Sepal.Length, iris$Sepal.Width) # -0.1175698
cor(iris$Sepal.Length, iris$Petal.Length) # 0.8717538
result <- lm(formula = Sepal.Length ~ Sepal.width, data = iris)
# 상관관계 분석
cor(iris$Sepal.Length, iris$Sepal.Width) # -0.1175698
cor(iris$Sepal.Length, iris$Petal.Length) # 0.8717538
result <- lm(formula = Sepal.Length ~ Sepal.width, data = iris)
result <- lm(formula = Sepal.Length ~ Sepal.Width, data = iris)
summary(result)
result2 <- lm(formula = Sepal.Length ~ Petal.Length, data = iris)
summary(result2)
m <- lm(dist ~ speed, cars)
m
names(m)
coef(m)
fitted(m)[1:4] + residuals(m)[1:4]
cars$dist[1:4]
# 회귀예측
coef(m)
newspeed = 3
coef(m)[1] + coef(m)[2] * newspeed
coef(m)[1] + coef(m)[2] * newspeed # 21.74499
predict(m, newdata = data.frame(speed = 10))
newspeed = 10
coef(m)[1] + coef(m)[2] * newspeed # 21.74499
predict(m, newdata = data.frame(speed = 10))
# 예측값의 신뢰구간
predict(m, newdata = data.frame(speed = 10), interval = 'confidence')
predict(m, newdata = data.frame(speed = 10), interval = 'predict')
plot(dist ~ speed, data = cars)
abline(m)
ci <- predict(m, interval = 'confidence')
lines(cars$speed, ci)
lines(cars$speed, ci)
plot(dist ~ speed, data = cars)
abline(m)
ci <- predict(m, interval = 'confidence')
lines(cars$speed, ci)
lines(cars$speed, ci[,3], col="blue")
plot(dist ~ speed, data = cars)
abline(m)
ci <- predict(m, interval = 'confidence')
lines(cars$speed, ci[,2], col="red")
lines(cars$speed, ci[,3], col="blue")
# anova로 두 모델 간 비교
full <- lm(dist ~ speed, data = cars)
full
reduced <- lm(dist ~ 1, data = cars)
reduced
anova(reduced, full) # p
plot(mfrow=c(2,2))
plot(,)
plot(m)
plot(mfrow=c(2,2))
plot(mfrow=c(2,2))
par(mfrow=c(2,2))
plot(m)
# Normal Q-Q plot으로 정규성 확인
res <- residuals(m)
res
shapiro.test(res)
shapiro.test(res) # p-value = 0.02152
states <- as.data.frame(state.x77[, c('Murder', 'Population', 'Illiteracy', 'Income', 'Frost')])
head(states)
dim(states)
# 다중회귀 모델
model <- lm(Murder ~ Population + Illiteracy + Income + Frost, data = states)
model
summary(model)
# 다중공신성 확인
install.packages('car', dependencies = T) # 종속적인 모든 패키지 설치
library(car)
vif(model) # 결과가 10을 넘으면 다중공선성 문제 발
vif(model) > 10
sqrt(vif(model))
# 이상 관측치 확인 - 제거 보다는 검토 대상이 되어야 함.
influencePlot(model, id.method = "identify")
# 회귀모형의 교정 관련 작업 ------------------
# 독립성을 만족하지 않는 경우
summary(powerTransform(states$Murder))
# 회귀모형의 교정 관련 작업 ------------------
# 독립성을 만족하지 않는 경우
summary(powerTransform(states$Murder))
boxplot(log(states$Murder), horizontal = T)
# 회귀모형의 교정 관련 작업 ------------------
# 독립성을 만족하지 않는 경우
boxplot(states$Murder, horizontal = T)
summary(powerTransform(states$Murder)) # P값 0.14512 > 0.05 독립성을 만족.
boxplot(log(states$Murder), horizontal = T)
# 회귀모형의 교정 관련 작업 ------------------
# 독립성을 만족하지 않는 경우
boxplot(states$Murder, horizontal = T)
summary(powerTransform(states$Murder)) # P값 0.14512 > 0.05 독립성을 만족.
boxplot(log(states$Murder), horizontal = T)
# 선형성을 만족하지 않는 경우.
boxTidwell(Murder ~ Population + Illiteracy, data = states)
# 등분산을 만족하지 않는 경우
ncvTest(model)
# 등분산성을 만족하지 않는다면
spreadLevelPlot(model)
summary(fit1)
# 등분산을 만족하지 않는 경우
ncvTest(model) # p = 0.18632 > 0.05 이므로 등분산성을 만족
# 등분산성을 만족하지 않는다면
spreadLevelPlot(model)
# 예측변수 선택 -- 가장 고민해야할 부분 중 하나 --
fit1 <- lm(Murder ~ ., data = status)
summary(fit1)
# 예측변수 선택 -- 가장 고민해야할 부분 중 하나 --
fit1 <- lm(Murder ~ ., data = status)
# 예측변수 선택 -- 가장 고민해야할 부분 중 하나 --
fit1 <- lm(Murder ~ ., data = status)
# 예측변수 선택 -- 가장 고민해야할 부분 중 하나 --
fit1 <- lm(Murder ~ ., data = states)
summary(fit1)
fit1 <- (Murder ~ Population + Illiteracy, data = states)
summary(fit1)
fit1 <- (Murder ~ Population + Illiteracy, data = states)
fit1 <- lm(Murder ~ Population + Illiteracy, data = states)
summary(fit1)
# 선형성을 만족하지 않는 경우.
boxTidwell(Murder ~ Population + Illiteracy, data = states)
# 등분산을 만족하지 않는 경우
ncvTest(model) # p = 0.18632 > 0.05 이므로 등분산성을 만족
# 등분산성을 만족하지 않는다면
spreadLevelPlot(model)
# 예측변수 선택 -- 가장 고민해야할 부분 중 하나 --
fit1 <- lm(Murder ~ ., data = states)
summary(fit1) # 설명력(Adjusted R-squared) :  0.5285
fit1 <- lm(Murder ~ Population + Illiteracy, data = states)
summary(fit1)
state.x77
states <- as.data.frame(state.x77[, c('Murder', 'Population', 'Illiteracy', 'Income', 'Frost')])
head(states)
dim(states)
# 다중회귀 모델
model <- lm(Murder ~ Population + Illiteracy + Income + Frost, data = states)
model
summary(model)
# 다중공신성 확인
install.packages('car', dependencies = T) # 종속적인 모든 패키지 설치.
library(car)
# 등분산을 만족하지 않는 경우
ncvTest(model) # p = 0.18632 > 0.05 이므로 등분산성을 만족
# 등분산성을 만족하지 않는다면
spreadLevelPlot(model)
# 선형성을 만족하지 않는 경우.
boxTidwell(Murder ~ Population + Illiteracy, data = states)
# 예측변수 선택 -- 가장 고민해야할 부분 중 하나 --
fit1 <- lm(Murder ~ ., data = states)
# 이상 관측치 확인 - 제거 보다는 검토 대상이 되어야 함.
influencePlot(model, id.method = "identify")
sqrt(vif(model)) # 결과가 2가 넘으면 다중공선성 문제 발생.
fit2 <- lm(Murder ~ Population + Illiteracy, data = states)
install.packages("car", dependencies = T)
summary(fit2)
summary(fit1) # 설명력(Adjusted R-squared) :  0.5285
# 회귀모형의 교정 관련 작업 ------------------
# 독립성을 만족하지 않는 경우
boxplot(states$Murder, horizontal = T)
boxplot(log(states$Murder), horizontal = T)
summary(powerTransform(states$Murder)) # P값 0.14512 > 0.05 독립성을 만족.
fit2 <- lm(Murder ~ Population + Illiteracy, data = states)
summary(fit2)
# 예측변수 선택2 - AIC 통계량
# Akaike 정보 기준. 값이 작을수록 더 나은 모델임.
AIC(fit1, fit2)
# stepwise regression : 단계적으로 회귀모형을 검정하면서 AIC 값을 비교 후 적합한 회귀모형을 찾아줌.
# AIC 값을 비교 후 적합한 회귀모형을 찾아줌.
full.model <- lm(Murder ~ ., data=states)
reduced.model <- step(full.model, direction = "backward")
# 추천값
# Step:  AIC=93.76 이 것이 최선이므로 제거작업 멈춤.
# Murder ~ Population + Illiteracy
summary(reduced.model)
# "forward" : 유익한 변수부터 추가.
min.model <- lm(Murder ~ 1, data=states)
fwd.model <- step(min.model, direction = "forward")
fwd.model <- step(min.model, direction = "forward", scope = (Murder ~ Population + Illiteracy + Income + Frost), trace = 1)
abc <- regsubsets(Murder ~ Population + Illiteracy + Income + Frost, data = states, nbset = 4)
abc
plot(abc, scale = "adjr2", main = "변수 선택 그래프")
abc <- regsubsets(Murder ~ Population + Illiteracy + Income + Frost, data = states, nbset = 4)
# 예측변수 선택 4 : all subset regression
library(leaps)
abc <- regsubsets(Murder ~ Population + Illiteracy + Income + Frost, data = states, nbset = 4)
abc <- regsubsets(Murder ~ Population + Illiteracy + Income + Frost, data = states, nbset = 4)
abc <- regsubsets(Murder ~ Population + Illiteracy + Income + Frost, data = states, nbest = 4)
abc
plot(abc, scale = "adjr2", main = "변수 선택 그래프")
# iris Datasets로 다중회귀분석
head(iris)
nrow(iris)
cor(iris[,-5])
# 학습데이터와 검정데이터로 분리(7:3)
sam_tt <- sample(1:nrow(iris), nrow(iris) * 0.7, replace = F)
train <- iris[sam_tt, ]
test <- iris[-sam_tt, ]
dim(train); dim(test)
# 회귀 모델
model <- lm(Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width, data = train)
model
summary(model)
# 다중 공선성
library(car)
vif(model)
model <- lm(Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width, data = train)
vif(model)
model <- lm(Sepal.Length ~ Sepal.Width + Petal.Width, data = train)
vif(model)
# 정규성
res <- residuals(model)
res
shapiro.test(res)
# 독립성
install.packages("lmtest")
library(lmtest)
dwtest(model)
par(mfrow = c(2,2))
plot(model)
summary(model)
dwtest(model) # DW = 2에 가까우면 독립성이 좋다.
y = 3.38155 + 0.42957 + 0.98060 * 0.2
y
head(test)
y = 3.38155 + 0.42957 * 3.1 + 0.98060 * 0.2
y
y = 3.38155 + 0.42957 * 3.1 + 0.98060 * 1.5
y
# 추정치 예측 : predict()
pred <- predict(model, test)
pred
head(test[,1], 2) # 실제값
head(pred, 2) # 예측값
mtcars
head(mtcars)
dim(mtcars)
# 단순회귀 예) hp(마력수)를 독립변수, mpg(연비)를 종속변수
cor(mtcars$hp, mtcars$mpg) # 강한음의 상관관계
plot(mpg ~ hp, data = mtcars)
lm <- lm(mpg ~ hp, data = mtcars)
abline(lm, col = 'blue')
lm
confint(lm)
summary()
summary(lm)
par(mfrow = c(2,2))
plot(lm)
par(mfrow = c(1,1))
y = 30.09886 + -0.06823 * 300
cat('예측 연비:', y)
mynew <- edit(mynew)
mynew <- mtcars[c(1,2),]
mynew <- edit(mynew)
mynew <- edit(mynew)
mynew <- mtcars[c(1,2),]
mynew <- edit(mynew)
mynew
pred <- predict(lm, newdata = mynew)
pred
# 다중회귀 예) hp(마력수)를 독립변수, mpg(연비)를 종속변수
lm2 <- lm(formula = mpg ~ hp + wt, data = mtcars)
ml2
lm2
summary(lm2)
pred2 <- predict(lm2)
pred2
mtcars$mpg[1]
pred[1]
df <- data.frame(mpg = mtcars$mpg, wt = 2.62)
df
# 마력수와 차체 무게를 입력해 예상 연비 추측
newCar <- data.frame(hp=110, wt=2.62) # 실제값으로 먼저 확인
newCar
predict(lm2, newdata = newCar)
# 22.8 4 108 93 3.85 2.320
newCar <- data.frame(hp=93, wt=2.32)
# 로지스틱 회귀 : 연속형 데이터를 이용해 결과를 그룹으로 분류()
mydata <- read.csv("http://stats.idre.ucla.edu/stat/data/binary.csv")
head(mydata)
summary(mydata)
mydata$admit <- factor(mydata$admit)
str(mydata) # 1이면 합격, 0이면 불합격
table(mydata$admit, mydata$rank)
xtabs(~admit + rank, data = mydata)
lgmodel <- glm(admit ~ ., data = mydata, family = "binomial")
lgmodel
summary(lgmodel)
# 분류 예측
head(mydata, 3)
ifelse(pred > 0.5, '합격','불합격')
# 분류 예측
head(mydata, 3)
pred <- predict(lgmodel, newdata = mydata, type = "response")
head(pred, 3)
ifelse(pred > 0.5, '합격','불합격')
# 새로운 값으로 분류예측
my <- mydata[c(1:3),]
my <- edit(my)
pred <- predict(lgmodel, newdata = my, type = "response")
pred
# 날씨 정보로 비 예측
weather <- read.csv("testdata/weather.csv", stringsAsFactors = F)
dim(weather)
head(weather)
str(weather)
weather_df <- weather(, c(-1, -6, -8, -14))
weather_df <- weather[, c(-1, -6, -8, -14)]
str(weather_df)
head(weather_df$RainTomorrow)
weather_df$RainTomorrow[weather$RainTomorrow == 'Yes'] <- 1
weather_df$RainTomorrow[weather$RainTomorrow == 'No'] <- 2
weather_df <- weather[, c(-1, -6, -8, -14)]
str(weather_df)
head(weather_df$RainTomorrow)
weather_df$RainTomorrow[weather_df$RainTomorrow == 'Yes'] <- 1
weather_df$RainTomorrow[weather_df$RainTomorrow == 'No'] <- 2
# 날씨 정보로 비 예측
weather <- read.csv("testdata/weather.csv", stringsAsFactors = F)
dim(weather)
head(weather)
str(weather)
weather_df <- weather[, c(-1, -6, -8, -14)]
str(weather_df)
head(weather_df$RainTomorrow)
weather_df$RainTomorrow[weather_df$RainTomorrow == 'Yes'] <- 1
weather_df$RainTomorrow[weather_df$RainTomorrow == 'No'] <- 2
weather_df$RainTomorrow <- as.numeric(weather_df$RainTomorrow)
str(weather_df)
head(weather_df)
weather <- read.csv("testdata/weather.csv", stringsAsFactors = F)
dim(weather)
head(weather)
str(weather)
weather_df <- weather[, c(-1, -6, -8, -14)]
str(weather_df)
head(weather_df$RainTomorrow)
weather_df$RainTomorrow[weather_df$RainTomorrow == 'Yes'] <- 1
weather_df$RainTomorrow[weather_df$RainTomorrow == 'No'] <- 0
weather_df$RainTomorrow <- as.numeric(weather_df$RainTomorrow)
str(weather_df)
head(weather_df)
# 자료를 7 : 3으로 분리
temp <- sample(1:nrow(weather_df), nrow(weather_df) * 0.7)
temp
train <- weather_df[temp,]
test <- weather_df[-temp,]
dim(train); dim(test)
weather_model <- glm(RainTomorrow ~ ., data = train, family = "binomial")
weather_model
summary(weather_model)
# 예측값 얻기
pred <- predict(weather_model, newdata = test, type='response')
head(pred, 20)
result_pred <- ifelse(pred >= 0.5, 1, 0)
result_pred
table(result_pred)
table(result_pred, test$RainTomorrow)
t <- table(result_pred, test$RainTomorrow)
t <- table(result_pred, test$RainTomorrow)
sum(diag(t) / nrow(test))
# ROC curve를 모델 평가
install.packages("ROCR")
library(ROCR)
pr <- prediction(pred, test$RainTomorrow)
prf <- performance(pr, measure = "tpr", x.measure = fpr)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
prf
plot(prf)
auc <- performance(pr, measure = "auc")
plot(auc)
auc
auc <- auc@y.values[[1]]
auc
ind <- sample(1:nrow(iris), nrow(iris) * 0.7, replace = F)
library(nnet)
m <- multinom(Species ~ ., data = train)
ind <- sample(1:nrow(iris), nrow(iris) * 0.7, replace = F)
train <- iris[ind, ]
test <- iris[-ind, ]
train
library(nnet)
m <- multinom(Species ~ ., data = train)
m$fitted.values
m_class <- max.col(m$fitted.values)
m_class
train
df <- data.frame(c(5,4,3), c(4,5,6), c(3,2,1))
df
max.col(df)
m$fitted.values
m_class <- max.col(m$fitted.values)
m_class
table(m_class)
table(train$Species, m_class)
pred <- predict(m, newdata = test, type = 'probe')
table(m_class)
table(train$Species, m_class)
pred <- predict(m, newdata = test, type = 'probe')
pred <- predict(m, newdata = test, type = 'probs')
pred
pred <- predict(m, newdata = test, type = 'class') # probs
table(pred)
table(pred, test$Species)
(13 + 18 + 13) / nrow(test)
install.packages("caret")
library(caret)
install.packa1ges("ㄷ1071")
install.packa1ges("e1071")
install.packa1ges("caret")
install.packa1ges("e1071")
library(caret)
library(e1071)
install.packa1ges("e1071")
install.packages("e1071")
library(e1071)
confusionMatrix(pred, test$Species)
my <- my[c(1,2,3),]
# 새로운 데이터로 분류 예측
my <- test
my <- my[c(1,2,3),]
my <- edit(my)
my
mypr <- predict(m, newdata = my, type = 'class')
mypr
table(mypr)
